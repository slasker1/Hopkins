{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6528ab",
   "metadata": {},
   "source": [
    "1. Explore the dataset, list number of rows and columns, check sanity, examine\n",
    "    features (e.g. histograms/plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2796c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cc = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "print(cc.head())\n",
    "#[5 rows x 31 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948e7a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n",
      "                Time            V1            V2            V3            V4  \\\n",
      "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
      "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
      "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
      "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
      "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
      "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
      "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
      "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
      "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
      "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
      "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
      "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
      "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
      "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
      "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
      "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
      "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
      "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
      "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
      "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
      "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
      "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
      "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
      "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
      "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
      "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
      "\n",
      "               Class  \n",
      "count  284807.000000  \n",
      "mean        0.001727  \n",
      "std         0.041527  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(cc.columns.tolist())\n",
    "\n",
    "#Examining the features\n",
    "#understanding the data set\n",
    "print(cc.info())\n",
    "#There are no null values!\n",
    "#dtypes: float64(30), int64(1)\n",
    "#28 objects, 1 Time, 1 Amount, 1 Class\n",
    "\n",
    "#Descriptive Statistics\n",
    "print(cc.describe())\n",
    "\n",
    "#More than one class for its label\n",
    "print(cc[\"Class\"].unique())\n",
    "#yes two classes 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa9d9667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.23000e+02, 9.07800e+03, 7.10230e+04, 1.52686e+05, 5.04660e+04,\n",
       "        1.19500e+03, 2.70000e+01, 8.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([-4.49894468, -3.16127605, -1.82360742, -0.48593879,  0.85172983,\n",
       "         2.18939846,  3.52706709,  4.86473572,  6.20240434,  7.54007297,\n",
       "         8.8777416 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.hist(cc['Class'])\n",
    "#Mostly 0 class\n",
    "#plt.hist(cc['Amount'])\n",
    "#Anamolies seen > 55000, normal dist good\n",
    "plt.hist(cc['V15'])\n",
    "#All of the V's are normally distributed between -number , to +number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65a246a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284315\n",
      "492\n"
     ]
    }
   ],
   "source": [
    "#2. \n",
    "# count values for class 0\n",
    "print(cc['Class'].value_counts()[0])\n",
    " \n",
    "# count values for class 1\n",
    "print(cc['Class'].value_counts()[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861951aa",
   "metadata": {},
   "source": [
    "3.Check if you need normalization or standardization, and justify. Complete preprocessing.\n",
    "\n",
    "Plotting the histogramns for each column on the V's & amount we realize that we need normalization since the distruibution of each of the features have different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd440206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy= 1.00\n",
      "\n",
      "Decision Tree accuracy= 1.00\n",
      "\n",
      "Random Forest accuracy= 1.00\n",
      "\n",
      "MLP accuracy= 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = cc['Class']\n",
    "X = cc.drop('Class', axis=1)\n",
    "\n",
    "#4. Split the dataset 50-50 for training and testing. Then run SVC,\n",
    "#DecisionTreeClassifier, MLPClassifier, RandomForest without any tree pruning or\n",
    "#regularization. Report the classification performance. \n",
    "\n",
    "X_train, X_test, Y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "#3. preprocessing using Min Max Scaler for normalization of the features\n",
    "sc = MinMaxScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "clf_svc = SVC(kernel='linear')\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_nn = MLPClassifier()\n",
    "\n",
    "clf_svc.fit(X_train, Y_train)\n",
    "clf_tree.fit(X_train, Y_train)\n",
    "clf_rf.fit(X_train, Y_train)\n",
    "clf_nn.fit(X_train, Y_train)\n",
    "\n",
    "svc_score = accuracy_score(y_test, clf_svc.predict(X_test))\n",
    "print(f'SVC accuracy= {svc_score:.2f}\\n')\n",
    "\n",
    "dt_score = accuracy_score(y_test, clf_tree.predict(X_test))\n",
    "print(f'Decision Tree accuracy= {dt_score:.2f}\\n')\n",
    "\n",
    "rf_score = accuracy_score(y_test, clf_rf.predict(X_test))\n",
    "print(f'Random Forest accuracy= {rf_score:.2f}\\n')\n",
    "\n",
    "nn_score = accuracy_score(y_test, clf_nn.predict(X_test))\n",
    "print(f'MLP accuracy= {dt_score:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd438c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Then run SVC,\n",
    "#DecisionTreeClassifier, MLPClassifier with tree pruning and regularization (Hint: might\n",
    "#use GridSearchCV to optimize the regularization parameters; or simply run a few pilot tests).\n",
    "#Report the classification performance.\n",
    "#Applying hyper parameters to each model TWICE\n",
    "\n",
    "\n",
    "#This takes a while to run be cautious\n",
    "#Takes too long to process hyperparameterization\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Creating the hyperparameter grid \n",
    "param_dist_svc = {\"kernel\": (\"linear\",\"poly\",\"rbf\"),\n",
    "                    \"C\": (0.1, 1, 10, 100, 1000),\n",
    "                     \"gamma\": (0.1, 1, 10, 100)}\n",
    "\n",
    "param_dist_tree = {\"max_depth\": randint(3, 12),\n",
    "                    \"max_features\": randint(3, 20)}\n",
    "    \n",
    "param_dist_rf = {\"max_depth\": randint(3, 12),\n",
    "                  \"max_features\": randint(3, 20),\n",
    "                  \"n_estimators\": randint(20,100)}\n",
    "    \n",
    "param_dist_nn = {\"hidden_layer_sizes\": randint(1,10),\n",
    "                  \"learning_rate\":('constant','invscaling','adaptive')}\n",
    "  \n",
    "# creating the RandomizedSearchCV object\n",
    "#svc_cv = RandomizedSearchCV(clf_svc, param_dist_svc, cv = 2)\n",
    "#tree_cv = RandomizedSearchCV(clf_tree, param_dist_tree, cv = 2)\n",
    "#forest_cv = RandomizedSearchCV(clf_rf, param_dist_rf, cv = 2)\n",
    "#nn_cv = RandomizedSearchCV(clf_nn, param_dist_nn, cv = 20)\n",
    "\n",
    "#svc_cv.fit(X_train, Y_train)\n",
    "#tree_cv.fit(X_train, Y_train)\n",
    "#forest_cv.fit(X_train, Y_train)\n",
    "#nn_cv.fit(X_train, y_train)\n",
    "  \n",
    "# Print the tuned parameters and score\n",
    "#print(\"Tuned SVC Parameters: {}\".format(svc_cv.best_params_))\n",
    "#print(\"Best score is {}\".format(svc_cv.best_score_))\n",
    "\n",
    "#print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "#print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "\n",
    "#print(\"Tuned Random Forest Parameters: {}\".format(forest_cv.best_params_))\n",
    "#print(\"Best score is {}\".format(forest_cv.best_score_))\n",
    "\n",
    "#print(\"Tuned Neural Network Parameters: {}\".format(nn_cv.best_params_))\n",
    "#print(\"Best score is {}\".format(nn_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07cd1cc",
   "metadata": {},
   "source": [
    "Tuned SVC Parameters: {'kernel': 'poly', 'gamma': 0.1, 'C': 10}\n",
    "Best score is 0.9993399016456115\n",
    "\n",
    "Tuned Decision Tree Parameters: {'max_depth': 5, 'max_features': 17}\n",
    "Best score is 0.9992977672086718\n",
    "\n",
    "Tuned Random Forest Parameters: {'max_depth': 11, 'max_features': 19, 'n_estimators': 81}\n",
    "Best score is 0.9994452361599439\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0da324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This takes a while to run be cautious\n",
    "#Takes too long to process hyperparameterization\n",
    "  \n",
    "# creating the RandomizedSearchCV object\n",
    "#nn_cv = RandomizedSearchCV(clf_nn, param_dist_nn, cv = 2)\n",
    "  \n",
    "#nn_cv.fit(X_train, Y_train)\n",
    "\n",
    "#print(\"Tuned Neural Network Parameters: {}\".format(nn_cv.best_params_))\n",
    "#print(\"Best score is {}\".format(nn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c7f6f",
   "metadata": {},
   "source": [
    "Tuned Neural Network Parameters: {'hidden_layer_sizes': 6, 'learning_rate': 'constant'}\n",
    "Best score is 0.9991573214196894"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278cb4f7",
   "metadata": {},
   "source": [
    "5. Script a PyTorch neural network with a hidden layer (might experiment with 2\n",
    "    hidden layers, size might be 20 to 40). Report the classification performance on the\n",
    "    previous 50-50 dataset. Expect a similar performance to the neural network in Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b562a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version= 1.11.0\n",
      "CUDA available= False\n",
      "30\n",
      "142403\n",
      "success\n",
      "MLP1 accuracy= 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f'PyTorch version= {torch.__version__}')\n",
    "print(f'CUDA available= {torch.cuda.is_available()}')\n",
    "\n",
    "class PyTorchMLP(torch.nn.Module):\n",
    "    def __init__(self, n_hidden=10, epochs=100, eta=0.001, minibatch_size=50, seed=0):\n",
    "        super(PyTorchMLP, self).__init__()\n",
    "        self.random = np.random.RandomState(seed)\n",
    "        self.n_hidden = n_hidden \n",
    "        self.epochs = epochs \n",
    "        self.eta = eta \n",
    "        self.minibatch_size = minibatch_size  \n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        self.model = None\n",
    "\n",
    "    def init_layers(self, _M, _K):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(_M, self.n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(self.n_hidden, self.n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Linear(self.n_hidden, _K)\n",
    "        )\n",
    "    \n",
    "    def predict(self, _X):\n",
    "        _X = torch.FloatTensor(_X)\n",
    "        assert self.model != None\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = np.argmax(self.model(_X), axis=1)\n",
    "        self.model.train()\n",
    "        return y_pred.numpy()\n",
    "\n",
    "    def fit(self, _X_train, _y_train, info=False):\n",
    "        import sys\n",
    "        _X_train, _y_train = torch.FloatTensor(_X_train), torch.LongTensor(_y_train)\n",
    "        print(\"success\")\n",
    "        n_features= _X_train.shape[1]\n",
    "        n_output= np.unique(_y_train).shape[0]  \n",
    "        \n",
    "        self.init_layers(n_features, n_output)\n",
    "\n",
    "        self.optimizer = torch.optim.Rprop(self.model.parameters(), lr=self.eta)\n",
    "\n",
    "        totloss = 0\n",
    "        for i in range(self.epochs):\n",
    "            indices = np.arange(_X_train.shape[0])\n",
    "            self.random.shuffle(indices)  \n",
    "\n",
    "            for start_idx in range(0, indices.shape[0] - self.minibatch_size + 1, self.minibatch_size):\n",
    "                batch_idx = indices[start_idx:start_idx + self.minibatch_size]\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                net_out = self.model(_X_train[batch_idx])\n",
    "                \n",
    "                loss = self.loss_func(net_out, _y_train[batch_idx])\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                if info:\n",
    "                    sys.stderr.write(f\"\\r{i+1:03d} Loss: {loss.item():6.5f}\")\n",
    "                    sys.stderr.flush()\n",
    "        return self\n",
    "    \n",
    "print(X_train.shape[1])\n",
    "\n",
    "print(Y_train.shape[0])\n",
    "\n",
    "mlp1 = PyTorchMLP(n_hidden=2, epochs=100, eta=0.001, minibatch_size=X_train.shape[0]).fit(X_train, Y_train)\n",
    "\n",
    "mlp1_score = accuracy_score(y_test, mlp1.predict(X_test))\n",
    "print(f'MLP1 accuracy= {mlp1_score:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5fc564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "MLP2 accuracy= 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6. Add dropout to the PyTorch neural network and repeat the previous step.\n",
    "class MLP_2(PyTorchMLP):\n",
    "    def init_layers(self, _M, _K):\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(_M, self.n_hidden),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(self.n_hidden, self.n_hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(self.n_hidden, _K),\n",
    "        )\n",
    "\n",
    "\n",
    "mlp2 = MLP_2(n_hidden=2, epochs=2000, eta=0.0001, minibatch_size=X_train.shape[0]).fit(X_train, Y_train)\n",
    "\n",
    "mlp2_score = accuracy_score(y_test, mlp2.predict(X_test))\n",
    "print(f'MLP2 accuracy= {mlp2_score:.2f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc46c5",
   "metadata": {},
   "source": [
    "7. Evaluate the 10-fold cross validation of Random Forest and two PyTorch neural\n",
    "    network from Q5. and Q6. Comment about results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbc89959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#This takes a while to run be cautious\n",
    "\n",
    "tuned_rf = RandomForestClassifier(max_depth=11, max_features=19, n_estimators=81)\n",
    "\n",
    "#scores = cross_val_score(tuned_rf, X, y, cv=10)\n",
    "#acc_rf = scores.mean()\n",
    "#print(\"The accuracy of the Tuned Random Forest is \" + str(acc_rf*100) + \"%\")\n",
    "\n",
    "#scores_1 = cross_val_score(PyTorchMLP(n_hidden=2, epochs=100, eta=0.001, minibatch_size=X_train.shape[0]), X, y, cv=2)\n",
    "#acc_1 = scores.mean()\n",
    "#print(\"The accuracy of the MLP1 is \" + str(acc_1*100) + \"%\")\n",
    "\n",
    "#scores_2 = cross_val_score(MLP_2(n_hidden=2, epochs=2000, eta=0.0001, minibatch_size=X_train.shape[0]), X, y, cv=2)\n",
    "#acc_2 = scores.mean()\n",
    "#print(\"The accuracy of the MLP2 is \" + str(acc_2*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffd54b",
   "metadata": {},
   "source": [
    "The accuracy of the Tuned Random Forest is 99.93 %\n",
    "\n",
    "100% accuracy for both MLP1 and MLP2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
